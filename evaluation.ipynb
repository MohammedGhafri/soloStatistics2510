{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8049605411499436\n",
      "Precision 0.7734627831715211\n",
      "Recall 0.6988304093567251\n",
      "F1 0.7342549923195083\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy', accuracy_score(y,y_pred))\n",
    "print('Precision', precision_score(y,y_pred))\n",
    "print('Recall', recall_score(y,y_pred))\n",
    "print('F1',f1_score(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[475  70]\n",
      " [103 239]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole dataset: (887, 6) (887,)\n",
      "training set: (665, 6) (665,)\n",
      "test set: (222, 6) (222,)\n"
     ]
    }
   ],
   "source": [
    "print(\"whole dataset:\", X.shape, y.shape)\n",
    "print(\"training set:\", X_train.shape, y_train.shape)\n",
    "print(\"test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8243243243243243\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8243243243243243\n",
      "precision: 0.788235294117647\n",
      "recall: 0.7613636363636364\n",
      "f1 score: 0.7745664739884393\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"precision:\", precision_score(y_test, y_pred))\n",
    "print(\"recall:\", recall_score(y_test, y_pred))\n",
    "print(\"f1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use a random_state parameter to ensure that we get the same random split every time the same code is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = [[1, 1], [2, 2], [3, 3], [4, 4]]\n",
    "# y = [0, 0, 1, 1]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=27)\n",
    "# print('X_train', X_train)\n",
    "# print('X_test', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [887, 222]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b3222a55e963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/soloStatistics2510/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/soloStatistics2510/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1434\u001b[0m                                     pos_label)\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/soloStatistics2510/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1248\u001b[0m                          str(average_options))\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/soloStatistics2510/.venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/soloStatistics2510/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [887, 222]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "print(precision_recall_fscore_support(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_recall_fscore_support\n",
    "\n",
    "sensitivity_score = recall_score\n",
    "def specificity_score(y_true, y_pred):\n",
    "    p, r, f, s = precision_recall_fscore_support(y_true, y_pred)\n",
    "    return r[0]\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"sensitivity:\", sensitivity_score(y_test, y_pred))\n",
    "print(\"specificity:\", specificity_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (model.predict_proba(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15872994, 0.76637881, 0.57989749, 0.35571893, 0.14818322,\n",
       "       0.14091187, 0.1789827 , 0.80813317, 0.48813437, 0.42318839,\n",
       "       0.53144534, 0.15240909, 0.77785729, 0.17203831, 0.06318716,\n",
       "       0.0500904 , 0.11881138, 0.70245914, 0.00996116, 0.11367827,\n",
       "       0.78158706, 0.40334166, 0.06416402, 0.43842006, 0.17804748,\n",
       "       0.68766885, 0.76366705, 0.73117037, 0.7328126 , 0.25894021,\n",
       "       0.17891373, 0.10035004, 0.86944645, 0.89633425, 0.20183623,\n",
       "       0.55564906, 0.04531941, 0.05953763, 0.31163404, 0.11027563,\n",
       "       0.56506704, 0.4127972 , 0.11367955, 0.76616956, 0.69647841,\n",
       "       0.6923965 , 0.30087993, 0.13387913, 0.28063781, 0.45035424,\n",
       "       0.63380257, 0.58848792, 0.18019356, 0.77986747, 0.27117506,\n",
       "       0.11407451, 0.62528059, 0.21024108, 0.55053357, 0.89951554,\n",
       "       0.70061553, 0.06162269, 0.12113741, 0.09593979, 0.95421315,\n",
       "       0.1683058 , 0.26998369, 0.40811902, 0.00863692, 0.15242545,\n",
       "       0.18776616, 0.0916033 , 0.0094988 , 0.12270213, 0.06204738,\n",
       "       0.41994848, 0.05935543, 0.10010868, 0.02968141, 0.14019657,\n",
       "       0.10064686, 0.74759534, 0.29928157, 0.11989115, 0.84322457,\n",
       "       0.81450175, 0.09599472, 0.11886716, 0.12950438, 0.80658155,\n",
       "       0.26062937, 0.17253546, 0.23168475, 0.60298132, 0.28952653,\n",
       "       0.17197146, 0.17281835, 0.03806678, 0.0447878 , 0.0916223 ,\n",
       "       0.86855458, 0.3805307 , 0.53327845, 0.70829118, 0.25004797,\n",
       "       0.9166392 , 0.18614438, 0.15242545, 0.12159482, 0.8798378 ,\n",
       "       0.94472844, 0.89548081, 0.37267777, 0.55102076, 0.29763956,\n",
       "       0.44934876, 0.43793783, 0.46585603, 0.60535478, 0.11877155,\n",
       "       0.93548791, 0.13022237, 0.4550678 , 0.10014181, 0.08871521,\n",
       "       0.94016524, 0.25250595, 0.96184943, 0.64193117, 0.68972833,\n",
       "       0.26190946, 0.36662553, 0.20891461, 0.18576616, 0.48349927,\n",
       "       0.24850297, 0.88856638, 0.6928103 , 0.91829858, 0.49710412,\n",
       "       0.87038583, 0.93445921, 0.11393154, 0.03643674, 0.55073736,\n",
       "       0.52955427, 0.8704403 , 0.18625969, 0.3110711 , 0.97931696,\n",
       "       0.10372985, 0.76719634, 0.94274492, 0.24602025, 0.14632782,\n",
       "       0.10459449, 0.11973064, 0.12904182, 0.77678104, 0.89774974,\n",
       "       0.03090402, 0.9505136 , 0.61383409, 0.26988853, 0.58504263,\n",
       "       0.65169609, 0.17195342, 0.79252732, 0.45532904, 0.12250274,\n",
       "       0.43261407, 0.61625028, 0.17884854, 0.70098923, 0.85665656,\n",
       "       0.35362613, 0.37795638, 0.35362613, 0.13473952, 0.57657016,\n",
       "       0.16526357, 0.90786515, 0.73873053, 0.13479425, 0.18950927,\n",
       "       0.88574832, 0.6909962 , 0.85426897, 0.73338346, 0.71980982,\n",
       "       0.37693564, 0.97684548, 0.15917929, 0.13320063, 0.52877031,\n",
       "       0.1658129 , 0.12371556, 0.17195342, 0.11763361, 0.90942114,\n",
       "       0.12888651, 0.34102213, 0.07560974, 0.9513358 , 0.9376881 ,\n",
       "       0.0737468 , 0.09016922, 0.70829118, 0.07767006, 0.5517331 ,\n",
       "       0.2714862 , 0.67951411, 0.08430094, 0.11368593, 0.2266949 ,\n",
       "       0.49265206, 0.63193737, 0.71000264, 0.15876539, 0.68979347,\n",
       "       0.16521638, 0.10932034])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_proba(X_test)[:,1]>0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.9761904761904762\n",
      "recall: 0.4659090909090909\n"
     ]
    }
   ],
   "source": [
    "print(\"precision:\", precision_score(y_test, y_pred))\n",
    "print(\"recall:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import precision_score, recall_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "# df['male'] = df['Sex'] == 'male'\n",
    "# X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "# y = df['Survived'].values\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# print(\"predict proba:\")\n",
    "# print(model.predict_proba(X_test))\n",
    "\n",
    "# y_pred = model.predict_proba(X_test)[:, 1] > 0.75\n",
    "\n",
    "# print(\"precision:\", precision_score(y_test, y_pred))\n",
    "# print(\"recall:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:,1])\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('1 - specificity')\n",
    "plt.ylabel('sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8976424694708277"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_proba[:,1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 AUC score :  0.8739164696611506\n",
      "model 2 AUC score :  0.8444094212415725\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male']=df['Sex'] == 'male'\n",
    "X= df[['Pclass','male','Age','Siblings/Spouses','Parents/Children','Fare']].values\n",
    "y=df['Survived'].values\n",
    "\n",
    "X_train,X_test, y_train , y_test= train_test_split(X,y)\n",
    "\n",
    "model1=LogisticRegression()\n",
    "model1.fit(X_train,y_train)\n",
    "y_pred_proba1= model1.predict_proba(X_test)\n",
    "print('model 1 AUC score : ', roc_auc_score(y_test,y_pred_proba1[:,1]))\n",
    "\n",
    "\n",
    "model2=LogisticRegression()\n",
    "model2.fit(X_train[:,0:2],y_train)\n",
    "y_pred_proba2 =model2.predict_proba(X_test[:,0:2])\n",
    "\n",
    "print('model 2 AUC score : ', roc_auc_score(y_test, y_pred_proba2[:,1]))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy: 0.77928\n",
      "precision: 0.78082\n",
      "   recall: 0.63333\n",
      " f1 score: 0.69939\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "df['male'] = df['Sex'] == 'male'\n",
    "X = df[['Pclass', 'male', 'Age', 'Siblings/Spouses', 'Parents/Children', 'Fare']].values\n",
    "y = df['Survived'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# building the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluating the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\" accuracy: {0:.5f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"precision: {0:.5f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"   recall: {0:.5f}\".format(recall_score(y_test, y_pred)))\n",
    "print(\" f1 score: {0:.5f}\".format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Age', 'Fare']].values[:6]\n",
    "y = df['Survived'].values[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0, 1, 2, 4]), array([3, 5])),\n",
       " (array([0, 1, 3, 5]), array([2, 4])),\n",
       " (array([2, 3, 4, 5]), array([0, 1]))]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(kf.split(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 4 5] [1 3]\n",
      "[0 1 2 3] [4 5]\n",
      "[1 3 4 5] [0 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://sololearn.com/uploads/files/titanic.csv')\n",
    "X = df[['Age', 'Fare']].values[:6]\n",
    "y = df['Survived'].values[:6]\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "for train, test in kf.split(X):\n",
    "    print(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
